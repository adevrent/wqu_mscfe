{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unexpected HTTP response: <Response [403]>\n"
     ]
    },
    {
     "ename": "HTTPError",
     "evalue": "403 Client Error: Forbidden for url: https://api.twitter.com/2/tweets/search/all?expansions=author_id%2Cin_reply_to_user_id%2Creferenced_tweets.id%2Creferenced_tweets.id.author_id%2Centities.mentions.username%2Cattachments.poll_ids%2Cattachments.media_keys%2Cgeo.place_id%2Cedit_history_tweet_ids&tweet.fields=attachments%2Cauthor_id%2Ccontext_annotations%2Cconversation_id%2Ccreated_at%2Centities%2Cgeo%2Cid%2Cin_reply_to_user_id%2Clang%2Cpublic_metrics%2Ctext%2Cpossibly_sensitive%2Creferenced_tweets%2Creply_settings%2Csource%2Cwithheld%2Cedit_controls%2Cedit_history_tweet_ids&user.fields=created_at%2Cdescription%2Centities%2Cid%2Clocation%2Cname%2Cpinned_tweet_id%2Cprofile_image_url%2Cprotected%2Cpublic_metrics%2Curl%2Cusername%2Cverified%2Cverified_type%2Cwithheld&media.fields=alt_text%2Cduration_ms%2Cheight%2Cmedia_key%2Cpreview_image_url%2Ctype%2Curl%2Cwidth%2Cvariants%2Cpublic_metrics&poll.fields=duration_minutes%2Cend_datetime%2Cid%2Coptions%2Cvoting_status&place.fields=contained_within%2Ccountry%2Ccountry_code%2Cfull_name%2Cgeo%2Cid%2Cname%2Cplace_type&start_time=2021-03-21T00%3A00%3A00%2B00%3A00&end_time=2021-03-22T00%3A00%3A00%2B00%3A00&query=dogs+lang%3Aen+-is%3Aretweet&max_results=100",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/sscf/wqu_mscfe/Financial Data/M6/L1_req.ipynb Cell 1\u001b[0m line \u001b[0;36m<cell line: 17>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/home/sscf/wqu_mscfe/Financial%20Data/M6/L1_req.ipynb#W0sdnNjb2RlLXJlbW90ZQ%3D%3D?line=13'>14</a>\u001b[0m search_results \u001b[39m=\u001b[39m t\u001b[39m.\u001b[39msearch_all(query\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mdogs lang:en -is:retweet\u001b[39m\u001b[39m\"\u001b[39m, start_time\u001b[39m=\u001b[39mstart_time, end_time\u001b[39m=\u001b[39mend_time, max_results\u001b[39m=\u001b[39m\u001b[39m100\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/home/sscf/wqu_mscfe/Financial%20Data/M6/L1_req.ipynb#W0sdnNjb2RlLXJlbW90ZQ%3D%3D?line=15'>16</a>\u001b[0m \u001b[39m# Get all results page by page:\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/home/sscf/wqu_mscfe/Financial%20Data/M6/L1_req.ipynb#W0sdnNjb2RlLXJlbW90ZQ%3D%3D?line=16'>17</a>\u001b[0m \u001b[39mfor\u001b[39;00m page \u001b[39min\u001b[39;00m search_results:\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/home/sscf/wqu_mscfe/Financial%20Data/M6/L1_req.ipynb#W0sdnNjb2RlLXJlbW90ZQ%3D%3D?line=17'>18</a>\u001b[0m     \u001b[39m# Do something with the whole page of results:\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/home/sscf/wqu_mscfe/Financial%20Data/M6/L1_req.ipynb#W0sdnNjb2RlLXJlbW90ZQ%3D%3D?line=18'>19</a>\u001b[0m     \u001b[39m# print(page)\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/home/sscf/wqu_mscfe/Financial%20Data/M6/L1_req.ipynb#W0sdnNjb2RlLXJlbW90ZQ%3D%3D?line=19'>20</a>\u001b[0m     \u001b[39m# or alternatively, \"flatten\" results returning 1 tweet at a time, with expansions inline:\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/home/sscf/wqu_mscfe/Financial%20Data/M6/L1_req.ipynb#W0sdnNjb2RlLXJlbW90ZQ%3D%3D?line=20'>21</a>\u001b[0m     \u001b[39mfor\u001b[39;00m tweet \u001b[39min\u001b[39;00m ensure_flattened(page):\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/home/sscf/wqu_mscfe/Financial%20Data/M6/L1_req.ipynb#W0sdnNjb2RlLXJlbW90ZQ%3D%3D?line=21'>22</a>\u001b[0m         \u001b[39m# Do something with the tweet\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/home/sscf/wqu_mscfe/Financial%20Data/M6/L1_req.ipynb#W0sdnNjb2RlLXJlbW90ZQ%3D%3D?line=22'>23</a>\u001b[0m         \u001b[39mprint\u001b[39m(tweet)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.5/lib/python3.10/site-packages/twarc/client2.py:310\u001b[0m, in \u001b[0;36mTwarc2._search\u001b[0;34m(self, url, query, since_id, until_id, start_time, end_time, max_results, expansions, tweet_fields, user_fields, media_fields, poll_fields, place_fields, sort_order, next_token, granularity, sleep_between)\u001b[0m\n\u001b[1;32m    304\u001b[0m             log\u001b[39m.\u001b[39minfo(\n\u001b[1;32m    305\u001b[0m                 \u001b[39m\"\u001b[39m\u001b[39mDetected incomplete counts, restarting with \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    306\u001b[0m                 \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mlast_time_start\u001b[39m}\u001b[39;00m\u001b[39m as the new end_time\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    307\u001b[0m             )\n\u001b[1;32m    309\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 310\u001b[0m     \u001b[39mfor\u001b[39;00m response \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_paginated(url, params\u001b[39m=\u001b[39mparams):\n\u001b[1;32m    311\u001b[0m         \u001b[39m# Note that we're ensuring the appropriate amount of sleep is\u001b[39;00m\n\u001b[1;32m    312\u001b[0m         \u001b[39m# taken before yielding every item. This ensures that we won't\u001b[39;00m\n\u001b[1;32m    313\u001b[0m         \u001b[39m# exceed the rate limit even in cases where a response generator\u001b[39;00m\n\u001b[1;32m    314\u001b[0m         \u001b[39m# is not completely consumed. This might be more conservative\u001b[39;00m\n\u001b[1;32m    315\u001b[0m         \u001b[39m# than necessary.\u001b[39;00m\n\u001b[1;32m    316\u001b[0m         time\u001b[39m.\u001b[39msleep(sleep_between)\n\u001b[1;32m    318\u001b[0m         \u001b[39m# can't return without 'data' if there are no results\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.5/lib/python3.10/site-packages/twarc/client2.py:1618\u001b[0m, in \u001b[0;36mTwarc2.get_paginated\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1603\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_paginated\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m   1604\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   1605\u001b[0m \u001b[39m    A wrapper around the `get` method that handles Twitter token based\u001b[39;00m\n\u001b[1;32m   1606\u001b[0m \u001b[39m    pagination.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1615\u001b[0m \u001b[39m        generator[dict]: A generator, dict for each page of results.\u001b[39;00m\n\u001b[1;32m   1616\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1618\u001b[0m     resp \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mget(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1619\u001b[0m     page \u001b[39m=\u001b[39m resp\u001b[39m.\u001b[39mjson()\n\u001b[1;32m   1621\u001b[0m     url \u001b[39m=\u001b[39m args[\u001b[39m0\u001b[39m]\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.5/lib/python3.10/site-packages/twarc/decorators2.py:136\u001b[0m, in \u001b[0;36mcatch_request_exceptions.<locals>.new_f\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    133\u001b[0m \u001b[39mexcept\u001b[39;00m (requests\u001b[39m.\u001b[39mexceptions\u001b[39m.\u001b[39mRequestException, \u001b[39mConnectionError\u001b[39;00m) \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    134\u001b[0m     \u001b[39m# don't catch any HTTP errors since those are handled separately\u001b[39;00m\n\u001b[1;32m    135\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(e, requests\u001b[39m.\u001b[39mexceptions\u001b[39m.\u001b[39mHTTPError):\n\u001b[0;32m--> 136\u001b[0m         \u001b[39mraise\u001b[39;00m e\n\u001b[1;32m    138\u001b[0m     errors \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    139\u001b[0m     log\u001b[39m.\u001b[39mwarning(\u001b[39m\"\u001b[39m\u001b[39mcaught requests exception: \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m, e)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.5/lib/python3.10/site-packages/twarc/decorators2.py:130\u001b[0m, in \u001b[0;36mcatch_request_exceptions.<locals>.new_f\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[39mwhile\u001b[39;00m errors \u001b[39m<\u001b[39m tries:\n\u001b[1;32m    129\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 130\u001b[0m         resp \u001b[39m=\u001b[39m f(\u001b[39mself\u001b[39;49m, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    131\u001b[0m         errors \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[1;32m    132\u001b[0m         \u001b[39mreturn\u001b[39;00m resp\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.5/lib/python3.10/site-packages/twarc/decorators2.py:100\u001b[0m, in \u001b[0;36mrate_limit.<locals>.new_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     99\u001b[0m     log\u001b[39m.\u001b[39merror(\u001b[39m\"\u001b[39m\u001b[39mUnexpected HTTP response: \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m, resp)\n\u001b[0;32m--> 100\u001b[0m     resp\u001b[39m.\u001b[39;49mraise_for_status()\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.5/lib/python3.10/site-packages/requests/models.py:1021\u001b[0m, in \u001b[0;36mResponse.raise_for_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1016\u001b[0m     http_error_msg \u001b[39m=\u001b[39m (\n\u001b[1;32m   1017\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstatus_code\u001b[39m}\u001b[39;00m\u001b[39m Server Error: \u001b[39m\u001b[39m{\u001b[39;00mreason\u001b[39m}\u001b[39;00m\u001b[39m for url: \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39murl\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1018\u001b[0m     )\n\u001b[1;32m   1020\u001b[0m \u001b[39mif\u001b[39;00m http_error_msg:\n\u001b[0;32m-> 1021\u001b[0m     \u001b[39mraise\u001b[39;00m HTTPError(http_error_msg, response\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m)\n",
      "\u001b[0;31mHTTPError\u001b[0m: 403 Client Error: Forbidden for url: https://api.twitter.com/2/tweets/search/all?expansions=author_id%2Cin_reply_to_user_id%2Creferenced_tweets.id%2Creferenced_tweets.id.author_id%2Centities.mentions.username%2Cattachments.poll_ids%2Cattachments.media_keys%2Cgeo.place_id%2Cedit_history_tweet_ids&tweet.fields=attachments%2Cauthor_id%2Ccontext_annotations%2Cconversation_id%2Ccreated_at%2Centities%2Cgeo%2Cid%2Cin_reply_to_user_id%2Clang%2Cpublic_metrics%2Ctext%2Cpossibly_sensitive%2Creferenced_tweets%2Creply_settings%2Csource%2Cwithheld%2Cedit_controls%2Cedit_history_tweet_ids&user.fields=created_at%2Cdescription%2Centities%2Cid%2Clocation%2Cname%2Cpinned_tweet_id%2Cprofile_image_url%2Cprotected%2Cpublic_metrics%2Curl%2Cusername%2Cverified%2Cverified_type%2Cwithheld&media.fields=alt_text%2Cduration_ms%2Cheight%2Cmedia_key%2Cpreview_image_url%2Ctype%2Curl%2Cwidth%2Cvariants%2Cpublic_metrics&poll.fields=duration_minutes%2Cend_datetime%2Cid%2Coptions%2Cvoting_status&place.fields=contained_within%2Ccountry%2Ccountry_code%2Cfull_name%2Cgeo%2Cid%2Cname%2Cplace_type&start_time=2021-03-21T00%3A00%3A00%2B00%3A00&end_time=2021-03-22T00%3A00%3A00%2B00%3A00&query=dogs+lang%3Aen+-is%3Aretweet&max_results=100"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "\n",
    "from twarc.client2 import Twarc2\n",
    "from twarc.expansions import ensure_flattened\n",
    "\n",
    "# Your bearer token here\n",
    "t = Twarc2(bearer_token=\"AAAAAAAAAAAAAAAAAAAAAIf3qQEAAAAAOOK4ah83Ayuo%2BpUhZHIrFewC1vA%3DfCw0Q84v1Js43yxW8adzrH5MFmMmyXp3PStnlw7pb6iIwWfxUo\")\n",
    "\n",
    "# Start and end times must be in UTC\n",
    "start_time = datetime.datetime(2021, 3, 21, 0, 0, 0, 0, datetime.timezone.utc)\n",
    "end_time = datetime.datetime(2021, 3, 22, 0, 0, 0, 0, datetime.timezone.utc)\n",
    "\n",
    "# search_results is a generator, max_results is max tweets per page, 100 max for full archive search with all expansions.\n",
    "search_results = t.search_all(query=\"dogs lang:en -is:retweet\", start_time=start_time, end_time=end_time, max_results=100)\n",
    "\n",
    "# Get all results page by page:\n",
    "for page in search_results:\n",
    "    # Do something with the whole page of results:\n",
    "    # print(page)\n",
    "    # or alternatively, \"flatten\" results returning 1 tweet at a time, with expansions inline:\n",
    "    for tweet in ensure_flattened(page):\n",
    "        # Do something with the tweet\n",
    "        print(tweet)\n",
    "\n",
    "    # Stop iteration prematurely, to only get 1 page of results.\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NRCLex\n",
    "Emotional analysis library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nrclex import NRCLex"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLTK\n",
    "Natural Language Toolkit, natural language processing library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package twitter_samples to\n",
      "[nltk_data]     /home/sscf/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/twitter_samples.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download(\"twitter_samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['#FollowFriday', '@France_Inte', '@PKuchly57', '@Milipol_Paris', 'for', 'being', 'top', 'engaged', 'members', 'in', 'my', 'community', 'this', 'week', ':)']\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import twitter_samples\n",
    "\n",
    "positive_tweets = twitter_samples.strings('positive_tweets.json')\n",
    "negative_tweets = twitter_samples.strings('negative_tweets.json')\n",
    "text = twitter_samples.strings('tweets.20150430-223406.json')\n",
    "\n",
    "tweet_tokens = twitter_samples.tokenized('positive_tweets.json')[0]\n",
    "\n",
    "print(tweet_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /home/sscf/nltk_data...\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /home/sscf/nltk_data...\n",
      "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Normalization \n",
    "nltk.download('wordnet')\n",
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
