{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Heteroscedasticity**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let $\\epsilon_1, \\epsilon_2, \\ldots, \\epsilon_n$ a sequence of random variables where variance of each term is $Var(\\epsilon_i) = \\sigma_i^2$\n",
    "\n",
    "if $\\sigma_i^2 \\neq \\sigma_j^2$ for *some* $(i, j) : i \\neq j$ we conclude this sequence of random variables does not have constant variance and therefore the sequence is **heteroscedastic**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In an OLS regression model where\n",
    "\n",
    "$Y_i = \\beta_0 + \\beta_1 X_i + \\epsilon_i$ for $i = 0, 1, \\ldots, n$\n",
    "\n",
    "we assume the error terms $\\epsilon_1, \\epsilon_2, \\ldots, \\epsilon_n$ are iid and normally distributed with a mean of 0 and have constant variance, $\\epsilon_i$ ~ $N(0, \\sigma^2)$ for all $i$\n",
    "\n",
    "If the assumption is true, then we say this sequence of error terms are **homoscedastic**. However, if the empirical data shows us that the variance of error terms are **not** constant, then we decide the sequence is **heteroscedastic**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Demonstration and Diagram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define our functions to create simulated values\n",
    "\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "random.seed(314)  # fix seed for reproducibility purposes\n",
    "\n",
    "def genHetEpsilon(f, x):\n",
    "    \"\"\"Generates a normally distributed error term with mean 0 and variance a function of x,\n",
    "    var(epsilon) = f(x)\n",
    "\n",
    "    Args:\n",
    "        f (function): a function to be applied on x\n",
    "        x (float): represents an observation of a predictor variable X\n",
    "    \"\"\"\n",
    "    var = f(x)\n",
    "    return random.normalvariate(0, f(x)**0.5)\n",
    "\n",
    "x_arr = [random.uniform(0, 50) for i in range(100)]\n",
    "\n",
    "def genyValues(x_arr, f, beta_0, beta_1):\n",
    "    \"\"\"Generates y values as a linear function of x values \n",
    "    from x_arr with heteroscedastic error terms.\n",
    "    \n",
    "    y = beta_0 + beta_1 * x + epsilon\n",
    "\n",
    "    Args:\n",
    "        x_arr (list): a list of values, representing draws from a predictor variable X\n",
    "        f (function): a function to be applied on x to generate variance of error terms\n",
    "        beta_0 (float): intercept coefficient\n",
    "        beta_1 (float): slope coefficient\n",
    "    \"\"\"\n",
    "    return [beta_0 + beta_1*x + genHetEpsilon(f, x) for x in x_arr]\n",
    "\n",
    "def plotOLS(x_arr):\n",
    "    \"\"\"Create a scatterplot of x_arr and fitted values\n",
    "\n",
    "    Args:\n",
    "        x_arr (list): an array of numbers\n",
    "    \"\"\"\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    ax.scatter(x_arr, genyValues(x_arr, lambda x: 20*x, 10, 1), label=r\"$(x_i, y_i): y_i = \\beta_0 + \\beta_1 x_i + \\epsilon_i$\")\n",
    "    ax.set(title=\"OLS Scatterplot with Heteroscedasticity\")\n",
    "    ax.set_xlabel(r\"$x_i$\", fontsize=16)\n",
    "    ax.set_ylabel(r\"$y_i$\", fontsize=16)\n",
    "    ax.legend()\n",
    "    return fig, ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<Figure size 720x432 with 1 Axes>,\n",
       " <Axes: title={'center': 'OLS Scatterplot with Heteroscedasticity'}, xlabel='$x_i$', ylabel='$y_i$'>)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "random.seed(314)  # fix seed for reproducibility purposes\n",
    "\n",
    "# Generate an array of uniform draws between 0 and 50, of length 100 to simulate data; then print\n",
    "x_arr = [random.uniform(0, 50) for i in range(100)]\n",
    "\n",
    "# Plot our values where x values are draws from an independent standard uniform variable X\n",
    "# and y values are draws from a random variable Y where Y_i = beta_0 + beta_1 X_i + epsilon_i\n",
    "plotOLS(x_arr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, because we defined the variance of simulated error terms as $Var(\\epsilon_i) = 20 x_i$, our data has **heteroscedasticity**, showing increasing $Y_i$ variance with increasing $x_i$ values.\n",
    "\n",
    "Therefore, $Var(Y_i)$ has a **monotonic** relationship with $x_i^2$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Diagnosis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To decide whether our sequence of random variables is homoscedastic or **heteroscedastic**, we have several options available.\n",
    "\n",
    "* **Scatterplot inspection:** First, while doing an exploratory data analysis, we can just scatterplot the $y$ values against $x$ values and generate a visual. By inspecting the plot, if we observe a cone-like distribution of points, that is spread between points increases with increasing $x$ values, we decide that this distribution of $y$ values show **heteroscedasticity**. However, this method is a little bit subjective and informal.\n",
    "\n",
    "* **Breusch-Pagan Test:** The Breusch-Pagan test is used in statistics to test for **heteroscedasticity** in a linear regression model. This is a chi-square test which assumes variance of error terms $\\sigma^2_i$ have a **linear** relationship with independent variable values $x_i$. Its testing the hypotheses where:\n",
    "\n",
    "$\\qquad H_0:$ The sequence of error terms is **homoscedastic**\n",
    "\n",
    "$\\qquad H_1:$ The sequence of error terms is **heteroscedastic**\n",
    "\n",
    "$\\qquad$ Therefore after conducting the test, if $p < 0.05$, we reject the null hypothesis and decide the sequence of error terms is **heteroscedastic**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9.821564</td>\n",
       "      <td>22.309842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.573288</td>\n",
       "      <td>28.537098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.131938</td>\n",
       "      <td>10.072717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>31.406804</td>\n",
       "      <td>0.377447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11.711581</td>\n",
       "      <td>21.540031</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           x          y\n",
       "0   9.821564  22.309842\n",
       "1   5.573288  28.537098\n",
       "2   0.131938  10.072717\n",
       "3  31.406804   0.377447\n",
       "4  11.711581  21.540031"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import libraries\n",
    "import statsmodels.formula.api as smf\n",
    "import statsmodels.stats.api as sms\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "random.seed(314)  # fix seed for reproducibility purposes\n",
    "\n",
    "# Generate an array of uniform draws between 0 and 50, of length 100 to simulate data; then print\n",
    "x_arr = [random.uniform(0, 50) for i in range(100)]\n",
    "\n",
    "# Generate simulated y values with beta_0 = 10 and beta_1 = 1, just like above plot\n",
    "y_arr = genyValues(x_arr, lambda x: 20*x, 10, 1)\n",
    "\n",
    "# Combine them into a dataframe\n",
    "df = pd.DataFrame(np.array([x_arr, y_arr]).transpose(), columns=[\"x\", \"y\"])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared:         </th> <td>   0.289</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.281</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   39.76</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Mon, 27 Nov 2023</td> <th>  Prob (F-statistic):</th> <td>8.27e-09</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>15:22:39</td>     <th>  Log-Likelihood:    </th> <td> -442.81</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   100</td>      <th>  AIC:               </th> <td>   889.6</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>    98</td>      <th>  BIC:               </th> <td>   894.8</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     1</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>         <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th> <td>    9.6048</td> <td>    3.689</td> <td>    2.603</td> <td> 0.011</td> <td>    2.283</td> <td>   16.926</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x</th>         <td>    0.9761</td> <td>    0.155</td> <td>    6.306</td> <td> 0.000</td> <td>    0.669</td> <td>    1.283</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>11.576</td> <th>  Durbin-Watson:     </th> <td>   1.930</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.003</td> <th>  Jarque-Bera (JB):  </th> <td>  13.900</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 0.626</td> <th>  Prob(JB):          </th> <td>0.000959</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 4.329</td> <th>  Cond. No.          </th> <td>    43.0</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/latex": [
       "\\begin{center}\n",
       "\\begin{tabular}{lclc}\n",
       "\\toprule\n",
       "\\textbf{Dep. Variable:}    &        y         & \\textbf{  R-squared:         } &     0.289   \\\\\n",
       "\\textbf{Model:}            &       OLS        & \\textbf{  Adj. R-squared:    } &     0.281   \\\\\n",
       "\\textbf{Method:}           &  Least Squares   & \\textbf{  F-statistic:       } &     39.76   \\\\\n",
       "\\textbf{Date:}             & Mon, 27 Nov 2023 & \\textbf{  Prob (F-statistic):} &  8.27e-09   \\\\\n",
       "\\textbf{Time:}             &     15:22:39     & \\textbf{  Log-Likelihood:    } &   -442.81   \\\\\n",
       "\\textbf{No. Observations:} &         100      & \\textbf{  AIC:               } &     889.6   \\\\\n",
       "\\textbf{Df Residuals:}     &          98      & \\textbf{  BIC:               } &     894.8   \\\\\n",
       "\\textbf{Df Model:}         &           1      & \\textbf{                     } &             \\\\\n",
       "\\textbf{Covariance Type:}  &    nonrobust     & \\textbf{                     } &             \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lcccccc}\n",
       "                   & \\textbf{coef} & \\textbf{std err} & \\textbf{t} & \\textbf{P$> |$t$|$} & \\textbf{[0.025} & \\textbf{0.975]}  \\\\\n",
       "\\midrule\n",
       "\\textbf{Intercept} &       9.6048  &        3.689     &     2.603  &         0.011        &        2.283    &       16.926     \\\\\n",
       "\\textbf{x}         &       0.9761  &        0.155     &     6.306  &         0.000        &        0.669    &        1.283     \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lclc}\n",
       "\\textbf{Omnibus:}       & 11.576 & \\textbf{  Durbin-Watson:     } &    1.930  \\\\\n",
       "\\textbf{Prob(Omnibus):} &  0.003 & \\textbf{  Jarque-Bera (JB):  } &   13.900  \\\\\n",
       "\\textbf{Skew:}          &  0.626 & \\textbf{  Prob(JB):          } & 0.000959  \\\\\n",
       "\\textbf{Kurtosis:}      &  4.329 & \\textbf{  Cond. No.          } &     43.0  \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "%\\caption{OLS Regression Results}\n",
       "\\end{center}\n",
       "\n",
       "Notes: \\newline\n",
       " [1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   R-squared:                       0.289\n",
       "Model:                            OLS   Adj. R-squared:                  0.281\n",
       "Method:                 Least Squares   F-statistic:                     39.76\n",
       "Date:                Mon, 27 Nov 2023   Prob (F-statistic):           8.27e-09\n",
       "Time:                        15:22:39   Log-Likelihood:                -442.81\n",
       "No. Observations:                 100   AIC:                             889.6\n",
       "Df Residuals:                      98   BIC:                             894.8\n",
       "Df Model:                           1                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "Intercept      9.6048      3.689      2.603      0.011       2.283      16.926\n",
       "x              0.9761      0.155      6.306      0.000       0.669       1.283\n",
       "==============================================================================\n",
       "Omnibus:                       11.576   Durbin-Watson:                   1.930\n",
       "Prob(Omnibus):                  0.003   Jarque-Bera (JB):               13.900\n",
       "Skew:                           0.626   Prob(JB):                     0.000959\n",
       "Kurtosis:                       4.329   Cond. No.                         43.0\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit an OLS model to our dataframe\n",
    "model = smf.ols(\"y ~ x\", df).fit()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Values</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Lagrange multiplier statistic</th>\n",
       "      <td>2.305367e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>p-value</th>\n",
       "      <td>1.575411e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f-value</th>\n",
       "      <td>2.936151e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f p-value</th>\n",
       "      <td>4.301180e-07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     Values\n",
       "Lagrange multiplier statistic  2.305367e+01\n",
       "p-value                        1.575411e-06\n",
       "f-value                        2.936151e+01\n",
       "f p-value                      4.301180e-07"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Breusch-Pagan test\n",
    "\n",
    "# Name our result parameters for the test\n",
    "name = [\"Lagrange multiplier statistic\", \"p-value\", \"f-value\", \"f p-value\"]\n",
    "\n",
    "# Fit residuals (random draws of epsilon) against our exogenous variable x values with Breusch-Pagan\n",
    "test = sms.het_breuschpagan(model.resid, model.model.exog)\n",
    "\n",
    "# Construct a dataframe of results\n",
    "pd.DataFrame(test, index=name, columns=[\"Values\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because $p << 0.05$, we decide with significant confidence that our error terms **does not** have equal variances and our data shows **heteroscedasticity**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Damage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not accounting for **heteroscedastic** error terms and wrongly assuming all of them have the same variance may result in significant problems:\n",
    "\n",
    "* **Poor Model Fit and Predictive Power:** A model that assumes homoscedasticity when the data is heteroscedastic may have poor explanatory and predictive power. This is because it may fail to capture the underlying structure and variability in the data.\n",
    "\n",
    "* **Misleading Statistical Inference:** Standard statistical tests (like t-tests or F-tests) rely on assumptions of constant variance. Heteroscedasticity can lead to an underestimation or overestimation of the standard errors of coefficient estimates, resulting in misleading conclusions about the statistical significance of variables.\n",
    "\n",
    "* **Inaccurate Estimations:** Models assuming homoscedasticity, such as OLS regression, may produce inefficient, biased, or inconsistent estimations of parameters. This inaccuracy can be particularly problematic in regression models, where heteroscedasticity can lead to biased and inconsistent estimates of regression coefficients.\n",
    "\n",
    "* **Compromised Risk Assessment:** In financial contexts, where assessing and managing risk is crucial, heteroscedasticity often indicates that the risk (variance) changes over time or across different levels of an explanatory variable. Ignoring this can lead to underestimating or overestimating risk, which can have significant financial implications."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Directions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After conducting a heteroscedasticity test such as **Breusch-Pagan** or **White** and deciding our data shows heteroscedasticity; we can move on to solve the problem.\n",
    "\n",
    "A good way to handle heteroscedasticity is conducting a **Weighted Least Squares (WLS)** regression. In **WLS**, we can assign smaller weights to points where absolute value of the residuals are large (meaning error terms should have high variance) and assign larger weights to points where absolute value of the residuals are small. This means that the <u> weight $w_{i}$ will be inversely proportional to the variance of error term $Var(\\epsilon_i)$ </u>:\n",
    "\n",
    "$ \\mathrm{Var}(\\epsilon_{i}) = \\sigma_{i}^{2} = \\Large\\frac{\\sigma ^{2}}{w_{i}} $\n",
    "\n",
    "\n",
    "\n",
    "Moreover, if we have a statistically significant $p$ value from a Breusch-Pagan test, we can estimate the variance of error terms $\\hat{Var(\\epsilon_i)} = \\hat{\\sigma_i^2}$ as a **linear function** of observed exogenous variable values where:\n",
    "\n",
    "$\\hat{\\sigma_i^2} = \\gamma_0 + \\gamma_1 x_i$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To calculate our weight estimates, we first conduct an OLS regression and calculate our coefficient estimates $\\beta_0, \\beta_1$. We then fit our model and get residual values such that:\n",
    "\n",
    "$r_i = y_i - \\hat{y_i} = y_i - (\\hat{\\beta_0} + \\hat{\\beta_1} x_i) $\n",
    "\n",
    "where $r_i$ is the residual value and $\\hat{\\beta_0}, \\hat{\\beta_1}$ are our coefficient estimates. Because we can think of $r_i^2$ as the observed value of the true variance $\\sigma_i^2$, we can model residual values as a linear function of $x_i$ by using observed $r_i$ values from sample:\n",
    "\n",
    "$ Var(\\epsilon_i) = \\sigma_i^2 = r_i^2 = \\gamma_0 + \\gamma_1 x_i + u_i$\n",
    "\n",
    "where the objective function to be minimized is RSS: the residual sum of squares but here the residuals are $k_i = r_i^2 - \\hat{r_i^2}$ and **not** the same with $r_i$.\n",
    "\n",
    "$RSS(\\beta_0, \\beta_1) = \\sum_{i=1}^n k_i^2 = \\sum_{i=1}^n (r_i^2 - \\hat{r_i^2})^2 = \\sum_{i=1}^n (r_i^2 - (\\gamma_0 + \\gamma_1 x_i))^2 $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After we solve the minimization problem by setting the gradient to $\\bm{0}$, we get $\\hat{\\gamma_0}, \\hat{\\gamma_1}$ coefficient estimates. Then:\n",
    "\n",
    "$ \\hat{r_i^2} = \\hat{\\gamma_0} + \\hat{\\gamma_1} x_i = \\hat{\\sigma_i^2} $\n",
    "\n",
    "And thus we have our estimated $\\sigma_i^2$ values. After this, we can choose a constant $\\sigma_2$ such as $\\sigma_2 = 1$ and calculate our weights $w_i$:\n",
    "\n",
    "$w_i = \\Large\\frac{1}{\\hat{\\sigma_i^2}}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After we have our weights, we fit our WLS regression model such that our objective function to minimize is the following weighted residual sum of squares:\n",
    "\n",
    "$ RSS(\\beta_0, \\beta_1) = \\sum_{i=1}^n w_i r_i^2 = \\sum_{i=1}^n w_i (y_i - (\\beta_0 + \\beta_1 x_i))^2 $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Solving the minimization problem, we get new $\\hat{\\beta_0}, \\hat{\\beta_1}$ coefficient estimates for our WLS model and complete our fitting with the linear regression function:\n",
    "\n",
    "$\\hat{y_i} = \\hat{\\beta_0} + \\hat{\\beta_1} x_i $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can do all of these steps in Python using statsmodels module:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "import statsmodels.stats.api as sms"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
